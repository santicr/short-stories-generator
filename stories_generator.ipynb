{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Stories generator first approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temas = [\"aventura\", \"misterio\", \"ciencia ficción\", \"romance\", \"fantasía\"]\n",
    "generos = [\"comedia\", \"tragedia\", \"acción\", \"drama\", \"suspense\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_historia(tema, genero):\n",
    "    # Define una lista de posibles introducciones.\n",
    "    introducciones = [\"En un lejano reino\", \"En la ciudad de\", \"En un futuro distópico\", \"Había una vez\"]\n",
    "\n",
    "    # Selecciona una introducción aleatoria.\n",
    "    introduccion = random.choice(introducciones)\n",
    "\n",
    "    # Construye la historia base.\n",
    "    historia_base = f\"{introduccion}, {tema} {genero}.\"\n",
    "    \n",
    "    # Agrega un giro inesperado.\n",
    "    giros = [\"Pero lo que nadie sabía era que\", \"Sin embargo, todo cambió cuando\", \"De repente, un extraño evento ocurrió:\"]\n",
    "\n",
    "    historia_con_giro = f\"{historia_base} {random.choice(giros)} {tema} se enfrentó a un inesperado desafío.\"\n",
    "\n",
    "    return historia_con_giro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Historia Generada:\n",
      "\n",
      "En un lejano reino, misterio drama. Pero lo que nadie sabía era que misterio se enfrentó a un inesperado desafío.\n",
      "Historia guardada en 'historia_generada.txt'.\n"
     ]
    }
   ],
   "source": [
    "tema_elegido = input(\"Por favor, elige un tema: \").lower()\n",
    "genero_elegido = input(\"Por favor, elige un género: \").lower()\n",
    "\n",
    "\n",
    "if tema_elegido not in temas or genero_elegido not in generos:\n",
    "    print(\"Tema o género no válido. Por favor, elige uno de los temas y géneros disponibles.\")\n",
    "else:\n",
    "    # Generar la historia.\n",
    "    historia_generada = generar_historia(tema_elegido, genero_elegido)\n",
    "\n",
    "    # Mostrar la historia.\n",
    "    print(\"\\nHistoria Generada:\\n\")\n",
    "    print(historia_generada)\n",
    "\n",
    "    # Opcionalmente, guardar o imprimir la historia en un archivo.\n",
    "    opcion = input(\"¿Deseas guardar o imprimir la historia? (s/n): \").lower()\n",
    "    if opcion == \"s\":\n",
    "        with open(\"historia_generada.txt\", \"w\") as archivo:\n",
    "            archivo.write(historia_generada)\n",
    "            print(\"Historia guardada en 'historia_generada.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Cargar el modelo pre-entrenado GPT-2 y el tokenizador\n",
    "modelo = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizador = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Crear una historia base\n",
    "historia_base = \"En un lejano reino, un valiente caballero se aventuró\"\n",
    "\n",
    "# Generar texto con una longitud máxima más corta\n",
    "input_ids = tokenizador.encode(historia_base, return_tensors=\"pt\")\n",
    "attention_mask = torch.ones(input_ids.shape)\n",
    "outputs = modelo.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, attention_mask=attention_mask)\n",
    "\n",
    "historia_generada = tokenizador.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En un lejano reino, un valiente caballero se aventuró a la vida de la cosa de los cualquieros.\n",
      "\n",
      "\"I am not a man of the world, but I am a woman of a different world. I have been born in a world of men, and I know that I will be a part of it. But I do not know what I want to do with my life. It is not my business to\n"
     ]
    }
   ],
   "source": [
    "print(historia_generada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short stories generator second approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, TextGenerationPipeline, GPT2LMHeadModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: Short story genre!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi user!\n",
      "Welcome to the short story generator, please type your favorite genre!\n",
      "The genres are the following: \n",
      "romance\n",
      "adventure\n",
      "mystery-&-detective\n",
      "fantasy\n",
      "humor-&-comedy\n",
      "paranormal\n",
      "science-fiction\n"
     ]
    }
   ],
   "source": [
    "genres = [\"romance\", \"adventure\", \"mystery-&-detective\", \"fantasy\", \"humor-&-comedy\", \"paranormal\", \"science-fiction\"]\n",
    "\n",
    "print(\"Hi user!\")\n",
    "print(\"Welcome to the short story generator, please type your favorite genre!\")\n",
    "print(\"The genres are the following: \")\n",
    "\n",
    "for genre in genres:\n",
    "    print(genre)\n",
    "\n",
    "genre = input(\"Type the genre here: \")\n",
    "\n",
    "while genre not in genres:\n",
    "    print(\"Please type a genre that is on the list\")\n",
    "    genre = input(\"Type the genre here: \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aspis/gpt2-genre-story-generation\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "generator = TextGenerationPipeline(model=model, tokenizer=tokenizer)\n",
    "input_prompt = f\"<BOS> <{genre}>\"\n",
    "story = generator(input_prompt, max_length=400, do_sample=True,repetition_penalty=1.5, temperature=1.2, \n",
    "               top_p=0.95, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '<BOS> <fantasy> \"Not much,\" said Lizzie with a wry grin. He was smiling back, but Jax could tell that she seemed tired and hungry from everything she had just told him...and really didn\\'t know what to make of it though; not in the way we expected as longas her sister did you? She looked through the food items like bread on the counter tops: he ate them all down here then for breakfast when things started getting hot...like the ones with egg fried and fried eggs....the kitchen item they wanted to keep going over this day if everything went well, if everything wasn\\'t bad enough; at least his room-sized tray full would go up! What an awful mess! After about nine o\\'clock later one or two women came around talking—just before Jenny\\'s arrival during dinner (she\\'d still be there after eating), making their voices low pitched as loud without any effect whatsoever until her voice stopped crying sobs while she sat on a bench nearby where some kind OF weirdo had gone crazy. They chatted briefly under cover noise to try out being alone, but before anyone answered any comment she quickly became bored again by all those shouting now trying desperately since nobody ever talked outside anyway.\\' And the next morning on to my table of food supplies I asked Jenny why Kaitlin hadn called out once when they were leaving town. Not only that Mr OReilly would have never done such work to help me carry the dishes; but that was true even though they felt more confident now than ten years old that Jax found themselves in bed together too,\\' she replied  \\'It\\'s been ten years Mrs Ollivar!\\'  When everyone made their decision Jenny gave another brief account concerning herself how pleased she got involved because the fact Tarrana appeared quite impressed by Kita\\'s ability spoke volumes about Joi, and Jazmin...\\' Jennet kept laughing for several days, saying anything spoken correctly in total tone about both boys'}]\n"
     ]
    }
   ],
   "source": [
    "print(story)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
