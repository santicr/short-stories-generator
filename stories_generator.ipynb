{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short stories generator second approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, TextGenerationPipeline, GPT2LMHeadModel, AutoTokenizer\n",
    "from dotenv import dotenv_values\n",
    "from translate import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: Short story genre!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola usuario\n",
      "Bienvenido al generador de historias cortas!\n",
      "Los géneros disponibles son los siguientes: \n",
      "romance\n",
      "aventura\n",
      "misterio\n",
      "fantasia\n",
      "comedia\n",
      "paranormal\n",
      "ciencia-ficcion\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n",
      "Por favor ingresa el nombre del genero tal cual como aparece\n"
     ]
    }
   ],
   "source": [
    "genres = [\"romance\", \"adventure\", \"mystery-&-detective\", \"fantasy\", \"humor-&-comedy\", \"paranormal\", \"science-fiction\"]\n",
    "generos = [\"romance\", \"aventura\", \"misterio\", \"fantasia\", \"comedia\", \"paranormal\", \"ciencia-ficcion\"]\n",
    "mapa = {generos[i]:genres[i] for i in range(len(generos))}\n",
    "\n",
    "print(\"Hola usuario\")\n",
    "print(\"Bienvenido al generador de historias cortas!\")\n",
    "print(\"Los géneros disponibles son los siguientes: \")\n",
    "\n",
    "for genero in generos:\n",
    "    print(genero)\n",
    "\n",
    "genero = input(\"Escribe el genero aqui: \").lower()\n",
    "\n",
    "while genero not in generos:\n",
    "    print(\"Por favor ingresa el nombre del genero tal cual como aparece\")\n",
    "    genero = input(\"Escribe el genero aqui: \").lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body & output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Body of the code (Reading a trained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arreglar_historia(historia):\n",
    "    nueva_historia = \"\"\n",
    "    historia = historia.split()\n",
    "\n",
    "    for i in range(2, len(historia)):\n",
    "        if i != 2:\n",
    "            nueva_historia += \" \"\n",
    "        nueva_historia += historia[i]\n",
    "\n",
    "    return nueva_historia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_historia(genre):\n",
    "    model_name = dotenv_values(\".env\")[\"NAME\"]  # config = {\"USER\": \"foo\", \"EMAIL\": \"foo@example.org\"}\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generator = TextGenerationPipeline(model=model, tokenizer=tokenizer)\n",
    "    input_prompt = f\"<BOS> <{genre}>\"\n",
    "    story = generator(input_prompt, max_length=400, do_sample=True,repetition_penalty=1.5, temperature=1.2, \n",
    "                top_p=0.95, top_k=50)\n",
    "    \n",
    "    return story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "historia = generar_historia(mapa[genero])\n",
    "historia = historia[0][\"generated_text\"]\n",
    "historia = arreglar_historia(historia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traducir_texto(texto_ingles):\n",
    "    translator = Translator(from_lang='en', to_lang='es')\n",
    "    max_chars = 500  # Máximo de caracteres permitidos por la biblioteca\n",
    "\n",
    "    # Divide el texto en segmentos de máximo 500 caracteres\n",
    "    segmentos = [texto_ingles[i:i+max_chars] for i in range(0, len(texto_ingles), max_chars)]\n",
    "\n",
    "    # Traduce cada segmento y almacena las traducciones\n",
    "    traducciones = []\n",
    "    for segmento in segmentos:\n",
    "        traduccion_segmento = translator.translate(segmento)\n",
    "        traducciones.append(traduccion_segmento)\n",
    "\n",
    "    # Une las traducciones para obtener el texto completo traducido\n",
    "    texto_espanol = ' '.join(traducciones)\n",
    "\n",
    "    return texto_espanol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ¿Qué? -dije. Ella no podía hablarme, pero era obvio que decía esto; como si eso de alguna manera la convenciera de algo importante en cualquier nivel del mundo más allá de nuestra comprensión, para aquellos, sabía lo fuertes que se volvieron incluso cuando estábamos separados el uno del otro nuevamente después de caer en una situación en la que todo lo que nos rodeaba comenzaba a moverse y no se unía para ciertos eventos solo cuando llegaba la gente o acababa de ser reemplazado por otra persona dentro de su grupo -asintió David. su cabeza. Las palabras llegaron muy temprano, así que sonrió. Realmente lo hizo sonreír...¡habría pasado mucho tiempo antes de que hubiera otra manera! Se sentó en mi sofá tratando de sacar lo que parecía imposible porque nadie le contó por qué debió haber sucedido el incidente de anoche en Londres, que esto probablemente sea cierto para muchos miembros dentro de esta fiesta, y una vez más, la gente siempre se pone cosas que nunca están seguros de quién más aquí sabe algo interesante en absoluto ¡ Con algunas dudas rápidas, Peter regresó con una respuesta que podría tener sentido a menos que lo estuvieras empeorando! Esto llevó a Alex a retroceder hacia el Dr. Martin directamente a cada lado hacia mí, dando mi declaración exactamente 12 horas después, antes de dejarlo solo al lado, en lugar de llevar a Michael fuera de servicio conduciendo al lado. Mi mirada atravesó a Ian demasiado rápido, pero se mantuvo firme y escuché a Paul acercarse de nuevo sosteniendo mi mano. Luego, cuando pasé junto a ellos con maravilloso asombro por su repentina partida, desde su casa, Daniel recogió el pañuelo de Simón de su asiento junto a él.-Buena suerte haciéndote justicia. \"Su voz se quedó atrás y estaba muy distante pero firme con certeza. Una sonrisa se deslizó a través de él una vez que se supo que la primera presión arterial se acercaba a los dos dígitos. Se apoderó de ambas manos apretando la mía con fuerza mientras hablaba con cuidado\" Eso no le hace nada mal a nadie... aceptará su oferta, ya ha acordado hacernos una visita anticipada durante la recepción de mañana ning\" '¡Can Billie!' \"Me llevé a Andrew', mirando hacia atrás\n"
     ]
    }
   ],
   "source": [
    "print(traducir_texto(historia))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
